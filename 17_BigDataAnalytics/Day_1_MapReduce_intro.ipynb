{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What Is MapReduce?\n",
    "\n",
    "* MapReduce is a method for distributing a task across multiple nodes\n",
    "* Each node processes data stored on that node (Where possible)\n",
    "* Consists of two phases: \n",
    "    - Map\n",
    "    - Reduce\n",
    "    \n",
    "<img src=\"files/Figures/hadoop_8.png\" width=\"750cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What about the bandwith?\n",
    "\n",
    "<img src=\"files/Figures/hadoop_9.png\" width=\"1500cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Features of MapReduce\n",
    "\n",
    "* Automatic parallelization and distribution\n",
    "* Fault-tolerance\n",
    "* Status and monitoring tools\n",
    "* A clean abstraction for programmers\n",
    "    - MapReduce programs are usually written in Java\n",
    "* MapReduce abstracts all the **‘housekeeping’** away from the developer\n",
    "    - Developer can concentrate simply on writing the Map and Reduce functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MapReduce: The Mapper\n",
    "\n",
    "* Hadoop attempts to ensure that Mappers run on nodes which hold their portion of the data locally, to avoid network traffic\n",
    "    - Multiple Mappers run in parallel, each processing a portion of the input data\n",
    "* The Mapper reads data in the form of key/value pairs\n",
    "* It outputs zero or more key/value pairs\n",
    "    - ```map(in_key, in_value) -> (inter_key, inter_value) list```\n",
    "* The Mapper may use or completely ignore the input key\n",
    "    - For example, a standard pattern is to read a line of a file at a time\n",
    "        - The key is the byte offset into the file at which the line starts \n",
    "        - The value is the contents of the line itself\n",
    "        - Typically the key is considered irrelevant\n",
    "* If it writes anything at all out, the output must be in the form of key/value pairs\n",
    "* What can we do with a Mapper?\n",
    "    - Select part of the input\n",
    "    - transform the text to the right format\n",
    "    - Apply functions\n",
    "    - filters (outliers for instance)\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MapReduce Example: Word Count\n",
    "\n",
    "* Count the number of occurrences of each word in a large amount of input data\n",
    "```\n",
    "Map(input_key, input_value)\n",
    "   foreach word w in input_value:\n",
    "    emit(w, 1)```\n",
    "\n",
    "* Input to the Mapper\n",
    "```\n",
    "(3414, 'the cat sat on the mat')\n",
    "(3437, 'the aardvark sat on the sofa')\n",
    "```\n",
    "\n",
    "* Output from the Mapper\n",
    "```\n",
    "('the', 1), ('cat', 1), ('sat', 1), ('on', 1),\n",
    "('the', 1), ('mat', 1), ('the', 1), ('aardvark', 1),\n",
    "('sat', 1), ('on', 1), ('the', 1), ('sofa', 1)\n",
    "```\n",
    "\n",
    "<img src=\"files/Figures/hadoop_3.png\" width=\"500cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MapReduce: The Reducer\n",
    "\n",
    "* After the Map phase is over, all the intermediate values for a given intermediate key are combined together into a list\n",
    "*  This list is given to a Reducer\n",
    "    - There may be a single Reducer, or multiple Reducers\n",
    "    - All values associated with a particular intermediate key are guaranteed to go to the same Reducer\n",
    "    - The intermediate keys, and their value lists, are passed to the Reducer in sorted key order\n",
    "    - This step is known as the ‘shuffle and sort’\n",
    "* The Reducer outputs zero or more final key/value pairs\n",
    "    - These are written to HDFS\n",
    "    - In practice, the Reducer usually emits a single key/value pair for each input key\n",
    "* What can we do with a Reducer?\n",
    "    - nothing\n",
    "    - data aggregation\n",
    "    - descriptive statistics\n",
    "    - data ordering\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example Reducer: Sum Reducer\n",
    "\n",
    "* Add up all the values associated with each intermediate key:\n",
    "```\n",
    "reduce(output_key, intermediate_vals)\n",
    "   set count = 0\n",
    "   foreach v in intermediate_vals:\n",
    "       count += v\n",
    "   emit(output_key, count)\n",
    "```\n",
    "\n",
    "* Reducer output:\n",
    "```\n",
    "('aardvark', 1)\n",
    "('cat', 1)\n",
    "('mat', 1)\n",
    "('on', 2)\n",
    "('sat', 2)\n",
    "('sofa', 1)\n",
    "('the', 4)\n",
    "```\n",
    "\n",
    "<img src=\"files/Figures/hadoop_4.png\" width=\"350cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Putting It All Together\n",
    "\n",
    "* The overall word count process\n",
    "\n",
    "<img src=\"files/Figures/hadoop_5.png\" width=\"1500cm\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MapReduce: The Shuffing & Sorting\n",
    "\n",
    "* Shuffling is the process of transfering data from the mappers to the reducers\n",
    "* Shuffling can start even before the map phase has finished, to save some time\n",
    "* Sorting saves even more time for the reducer, helping it easily distinguish when a new reduce task should start. It simply starts a new reduce task, when the next key in the sorted input data is different than the previous.\n",
    "* Each reduce task takes a list of key-value pairs, but it has to call the reduce() method which takes a key-list(value) input, so it has to group values by key. \n",
    "* Easy when input data is pre-sorted (locally) in the map phase and simply merge-sorted in the reduce phase (since the reducers get data from many mappers).\n",
    "\n",
    "<img src=\"files/Figures/aIGRQ.png\" width=\"1500cm\">\n",
    "\n",
    "_Note that in the image shuffing is called copy phase_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Why Do We Care About Counting Words?\n",
    "\n",
    "* Word count is challenging over massive amounts of data\n",
    "    - Using a single compute node would be too time-consuming\n",
    "    - Using distributed nodes require moving data\n",
    "    - Number of unique words can easily exceed the RAM\n",
    "    - Would need a hash table on disk\n",
    "    - Would need to partition the results (sort and shuffle)\n",
    "* Fundamentals of statistics often are simple aggregate functions\n",
    "* Most aggregation functions have distributive nature\n",
    "    - e.g., max, min, sum, count, mean, variance, etc\n",
    "*  MapReduce breaks complex tasks down into smaller elements which can be executed in parallel"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
