{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small><i>Updated January 2018 - This notebook was created by [Santi Seguí](https://ssegui.github.io/). </i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "        <h2>Collaborative filtering:</h2>\n",
    "         <br>\n",
    "</div>\n",
    "<h3>Collaborative filtering</h3>\n",
    "        Collaborative filtering methods are based on collecting and analyzing a large amount of information on users’ behaviors, activities or preferences and predicting what users will like based on their similarity to other users. \n",
    "        <br><b>Hyphothesis: Similar users tend to like similar items.</b>\n",
    "        <br><b>Requires a user community.</b>\n",
    "        <br>\n",
    "        <br>Collaborative filtering can be of two types: User-based and Item-based.\n",
    "    <ul>\n",
    "        <li>User-based CF works like this: take a user U and a set of other users D whose ratings are similar to the ratings of the selected user U and use the ratings from those like-minded users to calculate a prediction for the selected user U.</li><br>\n",
    "        <li>In Item-based CF you build an item-item matrix determining relationships between pairs of items and using this matrix and data on the current user, infer the user’s taste. Typicaly used in the domain: people who buy x also buy y</li>\n",
    "        </ul>\n",
    "        <img src=https://dataaspirant.files.wordpress.com/2015/01/userbased.png width=700>\n",
    "        <center>Original source: https://dataaspirant.files.wordpress.com</center>\n",
    "        \n",
    "</div>\n",
    "\n",
    "It can be undersoond as a generalization of Supervised Classication:\n",
    "<img src=\"images/colResSys.png\" width=600>\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "<p><b>Several</b> cases but <b>one (or two main) </b> approaches\n",
    "<ol>\n",
    "\n",
    "<li>Memory-Based Methods (Neighborhood-based methods) </li>\n",
    "<li>Model-Based Methods</li>\n",
    "</ol>\n",
    "<br>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\"><a class=\"anchor\" id=\"what-is-a-recommender\"></a><h3>Neighborhood-based methods</h3><br></div>\n",
    "<img src=\"images/neighbourhood.png\" width=600>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\">\n",
    "<h3>so..., What do we need to build a recommendation system?</h3>\n",
    "</div>\n",
    "\n",
    "## Steps in order to create a CF - Recommender\n",
    "+ Data recollection\n",
    "+ Data filtering/cleaning\n",
    "+ Item/user similarity function\n",
    "+ Learning/Prediction funciton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "EXAMPLE: Movie Recommender System. User-Based Collaborative Filtering\n",
    "</div>\n",
    "</h1>\n",
    "Given an \"active user\" (Joan) and an item that has not been seen by the user, the goal is to estimate the rating for the item.\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Superman</td> \n",
    "    <td>Star Wars 1</td>\n",
    "    <td>Matrix</td>\n",
    "    <td>Spiderman</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Santi</td>\n",
    "    <td>3</td> \n",
    "    <td>3.5</td>\n",
    "    <td>4.5</td>\n",
    "    <td><font color=\"red\"><b>¿?</b></font></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User1</td>\n",
    "    <td>3.5</td> \n",
    "    <td>4</td>\n",
    "    <td>5</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User2</td>\n",
    "    <td>3</td> \n",
    "    <td><font color=\"red\"><b>¿?</b></font></td>\n",
    "    <td>4.5</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User3</td>\n",
    "    <td>3.5</td> \n",
    "    <td>5</td>\n",
    "    <td>3.5</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<br><br><br><br>\n",
    "\n",
    "<h3>How to measure similarity between users?</h3>\n",
    "The computation of the similarity between the items is one critical step in the CF algorithms. The basic idea in similarity computation between two users <i>a</i> and <i>b</i> is to first isolate the items commonly rated by both users (set <i>P</i>), and then to apply a similarity computation technique to determine the similarity.\n",
    "    <ul>\n",
    "    <li>Euclidean distance</li>\n",
    "    $$sim(a,b) = \\sqrt{\\sum_{p \\in P}{(r_{a,p} - r_{b,p})^2}}$$\n",
    "    <br>\n",
    "    <li>Pearson Correlation</li>\n",
    "    $$sim(a,b) = \\frac{\\sum_{p\\in P} (r_{a,p}-\\bar{r_a})(r_{b,p}-\\bar{r_b})}{\\sqrt{\\sum_{p \\in P}(r_{a,p}-\\bar{r_a})²}\\sqrt{\\sum_{p \\in P}(r_{b,p}-\\bar{r_b})²}}$$\n",
    "    <br>\n",
    "    <li>Cosine distance</li>\n",
    "    $$ sim(a,b) = \\frac{\\vec{a}· \\vec{b}}{|\\vec{a}| * |\\vec{b}|}$$\n",
    "    <br>\n",
    "    </ul>\n",
    "  \n",
    "<br>\n",
    "Where: \n",
    "\n",
    "* $sim(a,b)$ is the similarity between user \"a\" and user \"b\"\n",
    "* $P$ is the set of common rated movies by user \"a\" and \"b\"\n",
    "* $r_{a,p}$ is the rating of movie \"p\" by user \"a\"\n",
    "* $\\bar{r_a}$ is the mean rating given by user \"a\"\n",
    "\n",
    "<br>\n",
    "\n",
    "<h3>Some issues to take into accout</h3>\n",
    "<ul>\n",
    "<li>Pearson Correlation used to work better than euclidean distance since it is based more on the ranking than on the values.</li>\n",
    "<li>Cosine distance is usually used when our data is binary/unary, i.e. like vs. not like  or buy vs. not buy.</li>\n",
    "<li>What happens if two users have very few items in common?</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "<h3>How do we generate a prediction from the neighbour's ratings?</h3><br>\n",
    "\n",
    "$$pred(a,p) = \\frac{\\sum_{b \\in N}{sim(a,b)*(r_{b,p})}}{\\sum_{b \\in N}{sim(a,b)}}$$\n",
    "\n",
    "Example:\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td>Critic</td>\n",
    "    <td>$sim(a,b)$</td> \n",
    "    <td>Rating Movie1: $r_{b,p_1}$</td>\n",
    "    <td>$sim(a,b)*(r_{b,p_1})$</td>\n",
    "    <td>Rating Movie2: $r_{b,p_2}$</td>\n",
    "    <td>$sim(a,b)*(r_{b,p_2})$</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User1</td>\n",
    "    <td>0.99</td> \n",
    "    <td>3</td>\n",
    "    <td>2.97</td>\n",
    "    <td>2.5</td>\n",
    "    <td>2.48</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User2</td>\n",
    "    <td>0.38</td> \n",
    "    <td>3</td>\n",
    "    <td>1.14</td>\n",
    "    <td>3</td>\n",
    "    <td>1.14</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User3</td>\n",
    "    <td>0.89</td>\n",
    "    <td>4.5</td>\n",
    "    <td>4.0</td>\n",
    "    <td> - </td>\n",
    "    <td> - </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User4</td>\n",
    "    <td>0.92</td>\n",
    "    <td>3</td>\n",
    "    <td>2.77</td>\n",
    "    <td>3</td>\n",
    "    <td>2.77</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)*(r_{b,p})}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td>10.87</td>\n",
    "    <td></td>\n",
    "    <td>6.39</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td>3.18</td>\n",
    "    <td></td>\n",
    "    <td>2.29</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>$pred(a,p)$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td>3.41</td>\n",
    "    <td></td>\n",
    "    <td>2.79</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation: performance criterion</h3>\n",
    "Performance evaluation of recommendation systems is an entire topic all in itself. Some of the options include:<br>\n",
    "* $RMSE = \\sqrt{(\\frac{\\sum(\\hat{y}-y)^2}{n})}$\n",
    "<br>\n",
    "* Precision / Recall / F-scores\n",
    "* ROC curves\n",
    "* Cost curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Movilens Database\n",
    "We will work with the well known MovieLens dataset (http://grouplens.org/datasets/movielens/). This dataset was initially constructed to support participants in the Netflix Prize. Today, we can find several versions of this dataset with different amout of data, from 100k samples version to 20m sample version. Although performance on bigger dataset is expected to be better, we will work with the smallest dataset: MovieLens 100K Dataset (ml-100k-zip). Working with this lite version has the benefit of less computational costs\n",
    "\n",
    "With a unix machine the dataset can be downloaded with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip \n",
    "!unzip ml-100k.zip -d \"data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are working with a windows machine, please go to the website and download the 100k version and extract it to the subdirectory named \"data/ml-100k/\"\n",
    "\n",
    "Once you have downloaded and unzipped the file into a directory, you can create a DataFrame with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#NETFLIX REAL 50.000.000 usuaris and 100.000 items\n",
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "# Load Data set\n",
    "u_cols = ['user_id', 'age', 'sex', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "# the movies file contains columns indicating the movie's genres\n",
    "# let's only load the first three columns of the file with usecols\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# Construcció del DataFrame\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data = data[['user_id','title', 'movie_id','rating','release_date','sex','age']]\n",
    "\n",
    "\n",
    "print(\"La BD has \"+ str(data.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.user_id.nunique(),\" users\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's first explore the data set\n",
    "### Pandas and Python review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#### Create a function that allows us to divide the dataset into:\n",
    "#### training and test\n",
    "\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    df.loc[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "\n",
    "def create_train_test(df,key = 'user_id'):\n",
    "    df['for_testing'] = False\n",
    "    grouped = data.groupby(key, group_keys=False).apply(assign_to_set)\n",
    "    # dataframe used to train our model\n",
    "    data_train = data[grouped.for_testing == False]\n",
    "    # dataframe used to evaluate our model\n",
    "    data_test = data[grouped.for_testing == True]\n",
    "    return data_train, data_test\n",
    "\n",
    "data_train, data_test =  create_train_test(data)\n",
    "\n",
    "\n",
    "print(data_train.shape)\n",
    "print(data_test.shape)\n",
    "print(data_train.index & data_test.index)\n",
    "\n",
    "print(\"Training data_set has \"+ str(data_train.shape[0]) +\" ratings\")\n",
    "print(\"Test data set has \"+ str(data_test.shape[0]) +\" ratings\")\n",
    "print(\"La BD has \", data.movie_id.nunique(), \" movies\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to get the set of movies from user with id  \"1\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train[data_train.user_id==1].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Rating of movies seen by user \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train[data_train.user_id==1].rating.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean rating of movie with title \"Seven (Se7en) (1995)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train.rating[data_train.title==\"Seven (Se7en) (1995)\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which are the 10 most rated movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train.groupby('title').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which are the 10 movies with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train.groupby('title').rating.mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_train.groupby('title').rating.mean().sort_values().tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top movies rated more than 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "size = data_train.groupby('title').size()\n",
    "mean_score = data_train.groupby('title').rating.mean()\n",
    "mean_score[size>10].sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which is the distibution of rated movies per user?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rated_movies = data_train.groupby('user_id').size().sort_values(ascending=False)\n",
    "rated_movies.hist(bins=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which is the mean movie scores per year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import isnan\n",
    "data_train['release_year'] = data_train['release_date'].apply(lambda x: int(str(x)[-4:]) \n",
    "                                                                    if isnan(float(str(x)[-4:]))==False \n",
    "                                                                    else 2010)\n",
    "rank_per_year = data_train.groupby('release_year')['rating'].mean()\n",
    "plt.bar(rank_per_year.keys(), rank_per_year, facecolor='#9999ff', edgecolor='white')\n",
    "plt.ylabel(\"Mean Score\")\n",
    "plt.ylim((min(rank_per_year),max(rank_per_year)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which movies are most controversial amongst different ages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "users.age.hist(bins=100)\n",
    "plt.title(\"Distribution of users' ages\")\n",
    "plt.ylabel('count of users')\n",
    "plt.xlabel('age')\n",
    "plt.show()\n",
    "\n",
    "labels = ['0-9', '10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79']\n",
    "data_train['age_group'] = pd.cut(data_train.age, range(0, 81, 10), right=False, labels=labels)\n",
    "print(data_train[['movie_id','age', 'age_group']].head())\n",
    "\n",
    "print(data_train.groupby('age_group').agg({'rating': [np.size, np.mean]}).copy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter films that have received at least 250 ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_by_title = data.groupby('title').size()\n",
    "print(ratings_by_title[ratings_by_title >= 250].head())\n",
    "\n",
    "active_titles = ratings_by_title.index[ratings_by_title >= 250]\n",
    "print(active_titles[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain the mean ratings for each movie grouped by gender that have at least 250 ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_ratings = data.pivot_table('rating', index='title',columns='sex', aggfunc='mean')\n",
    "mean_ratings = mean_ratings.loc[active_titles]\n",
    "print(mean_ratings[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show films more valued by women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_female_ratings = mean_ratings.sort_values(by='F', ascending=False)\n",
    "top_female_ratings[:10].F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we wonder which movies are rated more differently between men and women. Which films have more different rating and are more highly valued by women? And the films preferred by men which doesn't liked women? What are the films that have generated the most discordant ratings, regardless of gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_ratings['diff'] = mean_ratings['M'] - mean_ratings['F']\n",
    "#Sort by'diff':  films have more different rating and are more highly valued by women\n",
    "sorted_by_diff = mean_ratings.sort_values(by='diff')\n",
    "print('Best for women\\n')\n",
    "print(sorted_by_diff[:15])\n",
    "\n",
    "#Switching the order we get the films preferred by men which doesn't liked women\n",
    "print('\\nBest for men\\n')\n",
    "print(sorted_by_diff[:-15:-1])\n",
    "\n",
    "# We can use standard deviation of the ratings to find the films that have generated the most discordant ratings, regardless of gender\n",
    "\n",
    "# Standard deviation of rating grouped by title\n",
    "print(\"\\nMovies with highest controversy:\")\n",
    "rating_std_by_title = data.groupby('title')['rating'].std()\n",
    "# Filter down to active_titles\n",
    "rating_std_by_title = rating_std_by_title.loc[active_titles]\n",
    "print(rating_std_by_title.sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function called  <b>top_movies</b> that given a user it returns what movies have the highest rank for this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def top_movies(dataFrame,usr):\n",
    "    max_i = dataFrame[dataFrame.user_id == usr].rating.max() \n",
    "    print(\"Max puntuation of user\", usr, \"is:\", max_i)\n",
    "    return dataFrame[(dataFrame['user_id'] == usr) & (dataFrame['rating'] == max_i )].title\n",
    "\n",
    "print(top_movies(data,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Which is the similarity between user 1 and user 2?\n",
    "Let's look first for the common seen movies by the users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dataframe with the data from user 1\n",
    "data_user_1 = data_train[data_train.user_id==1]\n",
    "# dataframe with the data from user 2\n",
    "data_user_2 = data_train[data_train.user_id==2]\n",
    "# We first compute the set of common movies\n",
    "common_movies = set(data_user_1.movie_id).intersection(data_user_2.movie_id)\n",
    "print(\"\\nNumber of common movies\",len(common_movies),'\\n')\n",
    "\n",
    "# creat the subdataframe with only with the common movies\n",
    "mask = data_user_1.movie_id.isin(common_movies)\n",
    "data_user_1 = data_user_1[mask]\n",
    "print(data_user_1[['title','rating']].head())\n",
    "\n",
    "mask = (data_user_2.movie_id.isin(common_movies))\n",
    "data_user_2 = data_user_2[mask]\n",
    "print(data_user_2[['title','rating']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = pd.merge(data_user_1[['user_id','movie_id','rating']],data_user_2[['user_id','movie_id','rating']],on='movie_id')\n",
    "r.rating_y,r.rating_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's define a function to compute the users similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def SimEuclid(DataFrame,User1,User2,min_common_items=1):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id'] ==User1 ]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id'] ==User2 ]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1 ,movies_user2,on='movie_id')    \n",
    "    if len(rep)==0:\n",
    "        return 0\n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0\n",
    "    #return distEuclid(rep['rating_x'],rep['rating_y']) \n",
    "    return 1.0/(1.0+euclidean(rep['rating_x'],rep['rating_y'])) \n",
    "\n",
    "# Returns a pearsonCorrealation-based similarity score for person1 and person2\n",
    "def SimPearson(DataFrame,User1,User2,min_common_items=1):\n",
    "    # GET MOVIES OF USER1\n",
    "    movies_user1=DataFrame[DataFrame['user_id'] ==User1 ]\n",
    "    # GET MOVIES OF USER2\n",
    "    movies_user2=DataFrame[DataFrame['user_id'] ==User2 ]\n",
    "    \n",
    "    # FIND SHARED FILMS\n",
    "    rep=pd.merge(movies_user1 ,movies_user2,on='movie_id',)\n",
    "    if len(rep)==0:\n",
    "        return 0    \n",
    "    if(len(rep)<min_common_items):\n",
    "        return 0    \n",
    "    res=pearsonr(rep['rating_x'],rep['rating_y'])[0]\n",
    "    if(isnan(res)):\n",
    "        return 0\n",
    "    return res\n",
    "\n",
    "print(SimPearson(data_train,1,2))\n",
    "print(SimEuclid(data_train,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-error\" style = \"border-radius:10px;border-width:3px;border-color:darkred;font-family:Verdana,sans-serif;font-size:14px;\">\n",
    "<h2> Let's build the first CF-Recommender System</h2>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CollaborativeFiltering:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self,DataFrame, similarity=SimPearson):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_method=similarity# Gets recommendations for a person by using a weighted average\n",
    "        self.df = DataFrame\n",
    "        self.sim = pd.DataFrame(np.sum([0]),columns=data_train.user_id.unique(), index=data_train.user_id.unique())\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\" Prepare data structures for estimation. Similarity matrix for users \"\"\"\n",
    "        allUsers=set(self.df['user_id'])\n",
    "        self.sim = {}\n",
    "        for person1 in allUsers:\n",
    "            self.sim.setdefault(person1, {})\n",
    "            df_user = data_train[data_train['user_id']==person1][['movie_id']]\n",
    "            # Speedup trick - Dataframe that contain only those movies seen by person1\n",
    "            data_reduced = pd.merge(data_train, df_user, on='movie_id')\n",
    "            for person2 in allUsers:\n",
    "                # no es comparem am nosalres mateixos\n",
    "                if person1==person2: continue\n",
    "                self.sim.setdefault(person2, {})\n",
    "                if(person1 in self.sim[person2]):continue # since is a simetric matrix\n",
    "                sim = self.sim_method(data_reduced,person1,person2)\n",
    "                if(sim<0):\n",
    "                    self.sim[person1][person2]=0\n",
    "                    self.sim[person2][person1]=0\n",
    "                else:\n",
    "                    self.sim[person1][person2]=sim\n",
    "                    self.sim[person2][person1]=sim\n",
    "                \n",
    "    def estimate(self, user_id, movie_id):\n",
    "        ''' Estimate the rating of the movie_id for the user_id'''\n",
    "        totals={}\n",
    "        movie_users=self.df[self.df['movie_id'] ==movie_id]\n",
    "        rating_num=0.0\n",
    "        rating_den=0.0\n",
    "        allUsers=set(movie_users['user_id'])\n",
    "        for other in allUsers:\n",
    "            if user_id==other: continue \n",
    "            rating_num += self.sim[user_id][other] * float(movie_users[movie_users['user_id']==other]['rating'])\n",
    "            rating_den += self.sim[user_id][other]\n",
    "        if rating_den==0: \n",
    "            if self.df.rating[self.df['movie_id']==movie_id].mean()>0:\n",
    "                # return the mean movie rating if there is no similar for the computation\n",
    "                return self.df.rating[self.df['movie_id']==movie_id].mean()\n",
    "            else:\n",
    "                # else return mean user rating \n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "        return rating_num/rating_den\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a small dataset in order to reduce the computation cost and speedup the calculus in the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataSmall = data[data['user_id']<100].copy() # get only data from 100 users\n",
    "print(\"Now this dataset contains\", dataSmall.shape[0],'samples')\n",
    "\n",
    "dataSmall_train, dataSmall_test =  create_train_test(dataSmall)\n",
    "\n",
    "print(\"#Training samples = \",dataSmall_train.shape[0])\n",
    "print(\"#Test samples = \",dataSmall_test.shape[0])\n",
    "print('#Users =', dataSmall.user_id.nunique())\n",
    "print('#Movies =',dataSmall.movie_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reco = CollaborativeFiltering(dataSmall_train)\n",
    "reco.learn()\n",
    "reco.estimate(user_id=2,movie_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(estimate_f,data_train,data_test):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    ids_to_estimate = zip(data_test.user_id, data_test.movie_id)\n",
    "    estimated = np.array([estimate_f(u,i) if u in data_train.user_id else 3 for (u,i) in ids_to_estimate ])\n",
    "    real = data_test.rating.values\n",
    "    return compute_rmse(estimated, real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('RMSE for Collaborative Recomender: %s' % evaluate(reco.estimate,dataSmall_train,dataSmall_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h3><br><b>How improve the this recommender system?</b></h3>\n",
    "<h4> 1) Normalization: Predicitions scaled to the user domain.</h4><br>\n",
    "Users rate differntly, some rate high, while other low. This is the prediction function that was used in the original in Netflix system. Using this function we are scaling the prediction to our mean.<br>\n",
    "\n",
    "$$pred(a,p) = \\bar{r_a} + \\frac{\\sum_{b \\in N}{sim(a,b)*(r_{b,p}-\\bar{r_b})}}{\\sum_{b \\in N}{sim(a,b)}}$$\n",
    "<br>\n",
    "\n",
    "\n",
    "Example:<br>\n",
    "Preciction for the user \"a\" with  $\\bar{r_a} = 3.5$\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td>Critic</td>\n",
    "    <td>$sim(a,b)$</td> \n",
    "    <td>Mean Ratings: $\\bar{r_b}$</td>\n",
    "    <td>Rating Movie1: $r_{b,p_1}$</td>\n",
    "    <td>$sim(a,b)*(r_{b,p_1}-\\bar{r_b})$</td>\n",
    "\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User1</td>\n",
    "    <td>0.99</td> \n",
    "    <td>4.3</td> \n",
    "    <td>3</td>\n",
    "    <td>-1.28</td>\n",
    "\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User2</td>\n",
    "    <td>0.38</td> \n",
    "    <td>2.73</td> \n",
    "    <td>3</td>\n",
    "    <td>0.10</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User3</td>\n",
    "    <td>0.89</td>\n",
    "    <td>3.12</td>  \n",
    "    <td>4.5</td>\n",
    "    <td>1.22</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User4</td>\n",
    "    <td>0.92</td>\n",
    "    <td>3.98</td>  \n",
    "    <td>3</td>\n",
    "    <td>-0.90</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)*(r_{b,p}-\\bar{r_b})}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>-1.13</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>3.84</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>$pred(a,p)$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>3.20</td>\n",
    "\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "<h4> 2) Not all neighbor rating might be equally.</h4><br>\n",
    "Agreeement on commonly liked items is not as important as agreeement on controversial items. we can give a weigth correlated with the rating variance.\n",
    "\n",
    "<h4> 3) Value of number of co-rated items</h4>\n",
    "Reduce the similarity between users when the number of co-rated items is low or discard those users with a small number of co-rated items\n",
    "\n",
    "<h4> 4) Case amplificiation </h4>\n",
    "Increase the weigth to those users which are really really similars (~= 1)\n",
    "\n",
    "<h4> 5) Neighborhood selection</h4>\n",
    "Only a subset of similar user used to be used. Not-similar users used to be discarded\n",
    "\n",
    "<h4> 6) Recursive Methods</h4>\n",
    "In order to avoid cold-start we can apply a recursive method for new users.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<h3>Problems:</h3><br>\n",
    "<ul>\n",
    "<li>\"Memory-based\" approach</li>\n",
    "<li>Need to be trained offline and updateted periodically</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\">**EXERCISE 1**<p>\n",
    "Modify the Recomender System using as a prediction function the following equation:\n",
    "$$pred(a,p) = \\bar{r_a} + \\frac{\\sum_{b \\in N}{sim(a,b)*(r_{b,p}-\\bar{r_b})}}{\\sum_{b \\in N}{sim(a,b)}}$$\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "**EXERCISE 2:**<br>\n",
    "Modify the recomender system from the previous exercice, with one that in order to estimate the score of a movie B for the user A only uses the subset of the N most similar users to user A. Define N as a parameter of the Recoomender.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class  = \"alert alert-success\">**EXERCISE 3**<p>\n",
    "Modify the similarity function with the following:\n",
    "$$new\\_sim(a,b) = sim(a,b) * \\frac{min(50,|P_{ab}|)}{50} $$\n",
    "where $|P_{ab}|$ is the number of common items with user $a$ and user $b$\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
