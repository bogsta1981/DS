{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> \n",
    "# Computational Statistics for Data Analysis\n",
    "<font\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Probabilities. \n",
    "* 3.1 Probability rules\n",
    "* 3.2 Monte Carlo\n",
    "* 3.3 Continuous distribution\n",
    "* 3.4 Central limit Theorem\n",
    "* 3.5 Kernel density  (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Estimation\n",
    "* 4.1 Sample mean\n",
    "* 4.2 Variance\n",
    "* 4.3 Standard scores\n",
    "* 4.4 Covariance (optional)\n",
    "* 4.5 Pearson's correlation\n",
    "* 4.6 Spearman's rank correlation\n",
    " \n",
    "### 5 References\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "## 3 Probabilities  (frequentist point of view). \n",
    "* 3.1 Probability rules\n",
    "* 3.2 Monte Carlo\n",
    "* 3.3 Continuous distribution\n",
    "* 3.4 Central limit Theorem\n",
    "* 3.5 Kernel density\n",
    "<font\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common definition of **probability** is a *frequency expressed as a fraction* of the universe of possible outcomes. \n",
    "\n",
    "    Thus, it is a real value between 0 and 1 that is intended to be a measure corresponding to the idea that some things are more likely than others.\n",
    "\n",
    "The *things* we assign probabilities are called **events**, $E$.  A *situation* where $E$ might or might not happen is called a **trial**.\n",
    "\n",
    "   In the case of a six-sided die, each roll is called a **trial**. If we want to compute $P(6)$, each time a 6 appears is called a **success**. Other trials are called **failures**. \n",
    "\n",
    "If in a *finite series of $n$ identical trials* we observe $s$ successes, the **probability of the success** is $s/n$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Probability Rules \n",
    "\n",
    "A rule that is not always true: $P(A \\mbox{ and } B) = P(A) P(B)$. \n",
    "\n",
    "It is true, when $A$ and $B$ are **independent**. \n",
    "$A$ and $B$ are **independent** if the fact that $A$ occurred, does not change the probability of $B$ and viceversa. Trials corresponding to tossing a coin are independent. \n",
    "\n",
    "A rule that is true when $A$ and $B$ are **not independent**: \n",
    "\n",
    "$$ P(A|B) = \\frac{P(A \\mbox{ and } B)}{P(B)}$$\n",
    "\n",
    "From that we can derive: \n",
    "\n",
    "$$P(A \\mbox{ and } B) = P(A) P(B|A) = P(B) P(A|B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: \n",
    "\n",
    "+ If I have two children and we know that at least one of them is a girl, what is the probability that they are two girls?\n",
    "+ If I have two children and we know that the older one is a girl, what is the probability that they are two girls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More probability rules\n",
    "\n",
    "We say that two events are **mutually exclusive** if:\n",
    "\n",
    "$$ P(A | B) = P(B | A) = 0 $$\n",
    "\n",
    "In this case it is easy to show that:\n",
    "\n",
    "$$ P(A \\mbox{ or } B) = P(A) + P(B)$$\n",
    "\n",
    "If $A$ and $B$ are not mutually exclusive:\n",
    "\n",
    "$$ P(A \\mbox{ or } B) = P(A) + P(B) - P(A \\mbox{ and } B) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: Counting is the most basic skill to solve probability problems.\n",
    "\n",
    "+ Q: If I roll two dice and the total is 8, what is the probability that one of the dice is 6?\n",
    "+ Q: If I roll 100 dice, what is the probability of getting all sixes? \n",
    "+ Q: What is the probability of getting no sixes?\n",
    "+ Q: What is the probability of getting at least one six?\n",
    "+ Q: If I have two children, what is the probability that they are two girls?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Binomial distribution\n",
    "\n",
    "More generally, the probability distribution that represents the probability of getting $k$ times a success with probability $p$ in $n$ trials is:\n",
    "\n",
    "$$ PMF(k) = {n \\choose k} p^k (1-p)^{(n-k)}$$\n",
    "\n",
    "where ${n \\choose k} = \\frac{n!}{k!(n-k)!}$. This is called **binomial distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability of having 2 successes in 5 trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc as sc\n",
    "n = 5\n",
    "k = 2\n",
    "sc.comb(n, k, exact=True) # Chances of 2 successes in 5 trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability of having 5 heads in 9 trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chances of 5 heads in 9 tosses\n",
    "\n",
    "a = sc.comb(9, 5, exact=True)\n",
    "print('The combinations of 9 on 5 are: ', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "print('Prob: ', a * p**5 * (1-p)**4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability of having 6 sixes in 9 trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Monte Carlo Experiments\n",
    "\n",
    "**Monte Carlo experiments** are a broad class of computational algorithms that rely on *repeated random sampling to obtain numerical results*. Typically, one runs simulations many times over and over in order to obtain the distribution of an unknown probabilistic entity. (*Source: Wikipedia*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Trivial case**: What are the chances of getting a six in one trial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "N = 10000 # perform N experiments\n",
    "M = 0 # number of times, we got 6\n",
    "for i in range(N):\n",
    "    outcome = random.randint(1, 6)\n",
    "    if outcome == 6:\n",
    "        M += 1\n",
    "Prob=M/float(N)\n",
    "print('I got six %d times out of %d' % (M, N), '; Prob = ', \n",
    "      Prob, 'Note that: 1/6=', 1/6.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the chances of getting a six in two trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  chances of (exactly) 1 six in 2 trials\n",
    "\n",
    "a = sc.comb(2, 1, exact=True)\n",
    "p = 1/6.0\n",
    "print('Prob: ', a * p * (1-p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000 # perform N experiments\n",
    "M = 0 # no of times we get one 6\n",
    "for i in range(N):\n",
    "    outcome1 = random.randint(1, 6)\n",
    "    outcome2 = random.randint(1, 6)\n",
    "    if (outcome1 == 6 and outcome2 !=6) or (outcome1 != 6 and outcome2 == 6):\n",
    "        M += 1\n",
    "print('I got one six %d times out of %d' % (M, N), \n",
    "      '; Prob = ', float(M)/N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: You throw two dice, one black and one red. What is the probability\n",
    "that the number of eyes on the black die is larger than the number of\n",
    "eyes on the red die?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A more interesting case:** If I roll a dice 100 times, what is the chance of getting at least 6 sixes in a row?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What is the probability that Messi scores at least 1 goal in a row of 10 matches during a season? (Let's suppose that each match is an independent trial).\n",
    "\n",
    "**Data**: Messi scores 0.83 goals per match (323 goals in 387 matches) and CR4 scores 0.62 (329 goals in 527 matches) goals per match.\n",
    "There are 42 matches in a season. \n",
    "\n",
    "<small>(Source: https://es.answers.yahoo.com/question/index?qid=20130928103148AAFQHsC)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Continous distributions\n",
    "\n",
    "So far, we have built **empirical distributions** (which represent the distributions of values in a sample), based on observations, but many real problems are well approximated by fitting **continous distributions functions (CDF)**. \n",
    "\n",
    "They are called in this way because the distribution is described by an analytic continuous function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 The exponential distribution\n",
    "\n",
    "The CDF of the exponential distribution is:\n",
    "\n",
    "$$ CDF(x) = 1 -  \\exp^{- \\lambda x}$$ \n",
    "\n",
    "And its PDF is:\n",
    "\n",
    "$$ PDF(x) = \\lambda \\exp^{- \\lambda x}$$\n",
    "\n",
    "The parameter $\\lambda$ determines the shape of the distribution, the mean of the distribution is $1/\\lambda$ and its variance is $1/\\lambda^2$. The median is $ln(2)/\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In real applications, exponential distributions appear when we have a series of events and estimate the events times, called interarrival times. When the events are equally likely to occur at any time, the interarrival times distribution used to get exponential distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, the following figure shows the CDF of the interarrival times of birth in an Australian hospital. 44 births were registered in 24 hours, so the rate is $\\lambda=0.0306$ births/minute. The mean of the exponential distribution is $1/\\lambda$, so the mean time between births is 32.7 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src='images/interarrivaltimes.png'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "l = 2\n",
    "x=np.arange(0,2.5,0.1)\n",
    "y= 1 - np.exp(-l*x)\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Exponential CDF: $\\lambda$ =%.2f' % l ,fontsize=15)\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('CDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "l = 2\n",
    "x=np.arange(0,2.5,0.1)\n",
    "y= l * np.exp(-l*x)\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Exponential PDF: $\\lambda$ =%.2f' % l, fontsize=15)\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('PDF', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of real world events that can be described with this distribution.\n",
    "* The time until a radioactive particle decays,\n",
    "* The time it takes before your next telephone call,\n",
    "* The time until default (on payment to company debt holders) in reduced form credit risk modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random variable $X$ of the lifelengths of some batteries is associated with a probability density function of the form:\n",
    "\n",
    "$$ PDF(x) = \\frac{1}{4} \\exp^{- \\frac{x}{4}}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0.25\n",
    "x=np.arange(0,25,0.1)\n",
    "y= l * np.exp(-l*x)\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Exponential: $\\lambda$ =%.2f' % l ,fontsize=15)\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('PDF',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 The normal distribution\n",
    "\n",
    "The **normal, or Gaussian distribution** is the most used one because it describes a lot of phenomena and because it is amenable for analysis. \n",
    "\n",
    "Its CDF has no closed-form expression and its more common representation is the PDF:\n",
    "\n",
    "$$ PDF(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp \\left(-\\frac{(x-\\mu)^2}{2 \\sigma^2} \\right)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=5 # mean\n",
    "s=1 # standard deviation\n",
    "x=np.arange(0,15,0.1)\n",
    "y=(1/(np.sqrt(2*np.pi*s*s)))*np.exp(-(((x-u)**2)/(2*s*s)))\n",
    "plt.plot(x,y,'-')\n",
    "plt.title('Gaussian PDF: $\\mu$=%.1f, $\\sigma$=%.1f' % (u,s),fontsize=15)\n",
    "plt.xlabel('x',fontsize=15)\n",
    "plt.ylabel('Probability density',fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:\n",
    "    * Measures of size of living tissue (length, height, skin area, weight);\n",
    "    * The length of inert appendages (hair, claws, nails, teeth) of biological specimens, in the direction of growth; presumably the thickness of tree bark also falls under this category;\n",
    "    * Certain physiological measurements, such as blood pressure of adult humans.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist much more distributions as: \n",
    "- the Pareto distribution (describing e.g. the distribution of wealth, cities sizes, sand particles, forest fires and earthquakes,\n",
    "- the lognormal distribution (describing the adult weights), etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Central Limit Theorem\n",
    "\n",
    "The normal distribution is also important, because it is involved in the Central Limit Theorem:\n",
    "\n",
    "> Take the mean of $n$ random samples from ANY arbitrary distribution with a $well$ $defined$ standard deviation $\\sigma$ and mean $\\mu$. As $n$ gets bigger the **distribution of the sample mean** will always converge to a Gaussian (normal) distribution with mean $\\mu$ and standard deviation $\\frac{\\sigma}{\\sqrt{n}}$.\n",
    "\n",
    "Colloquially speaking, the theorem states the distribution of an average tends to be normal, even when the distribution from which the average is computed is decidedly non-normal. This explains the ubiquity of the Gaussian distribution in science and statistics. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Uniform Distribution\n",
    "\n",
    "The uniform distribution is obviously non-normal.  Let's call it the $parent$ $distribution$.\n",
    "\n",
    "To compute an average, two samples are drawn ($n=2$), at random, from the parent distribution and averaged. Then another sample of two is drawn and another value of the average computed.  This process is repeated, over and over, and averages of two are computed.  \n",
    "\n",
    "Repeatedly taking more elements ($n = 3,4...$) from the parent distribution, and computing the averages, produces a normal probability density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, sharey=True, squeeze=True, figsize=(11, 5))\n",
    "x = np.linspace(0, 1, 100)\n",
    "for i in range(4):\n",
    "    f = np.mean(np.random.random((10000, i+1)), 1)\n",
    "    m, s = np.mean(f), np.std(f, ddof=1)\n",
    "    fn = (1/(s*np.sqrt(2*np.pi)))*np.exp(-(x-m)**2/(2*s**2))  # normal pdf            \n",
    "    ax[i].hist(f, 40, normed=True, color=[0, 0.2, .8, .6]) \n",
    "    ax[i].set_title('n=%d' %(i+1))\n",
    "    ax[i].plot(x, fn, color=[1, 0, 0, .6], linewidth=10)\n",
    "    \n",
    "plt.suptitle('Demonstration of the central limit theorem for a uniform distribution', y=1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Central Limit Theorem explains the importance of normal distributions in the real world. Many features and properties of the living beings depend on genetic and environmental factors which effect usually is additive. The measured features are sum of manny small effects that not necessarily follow the normal distributions, but their sum does follow according to the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Kernel density estimates \n",
    "\n",
    "In some instances, we may not be interested in the parameters of a particular distribution of data, but just a **continous representation** of the data at hand. In this case, we can estimate the distribution non-parametrically (i.e. making no assumptions about the form of the underlying distribution) using kernel density estimation.\n",
    "\n",
    "Several uses are defined:\n",
    "\n",
    "- Visualization - to explore the data by visualizing them and decide whether an estimated PDF is an appropriate model for the distribution.\n",
    "\n",
    "- Interpolation - if we have reasons to beleive that the distribution is smooth, we can apply the KDE to interpolate the density specially for values that were not sampled.\n",
    "\n",
    "- Simulation - specially when the sample distribution is small, it would be convenient to smooth the sample distribution by KDE in order to simulated and explore more possible outcomes, rather than replicating the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.distributions import norm\n",
    "\n",
    "# Some random data\n",
    "y = np.random.random(15) * 10\n",
    "x = np.linspace(0, 10, 100)\n",
    "# Smoothing parameter\n",
    "s = 0.4\n",
    "\n",
    "# Calculate the kernels\n",
    "kernels = np.transpose([norm.pdf(x, yi, s) for yi in y])\n",
    "\n",
    "plt.plot(x, kernels, 'k:')\n",
    "plt.plot(x, kernels.sum(1))\n",
    "plt.plot(y, np.zeros(len(y)), 'ro', ms=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SciPy implements a Gaussian KDE that automatically chooses an appropriate bandwidth. Let's create a bi-modal distribution of data that is not easily summarized by a parametric distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bi-modal distribution with a mixture of Normals.\n",
    "x1 = np.random.normal(0, 3, 100) # parameters: (loc=0.0, scale=1.0, size=None)\n",
    "x2 = np.random.normal(8, 1, 50)\n",
    "\n",
    "# Append by row\n",
    "x = np.r_[x1, x2] # r_ Translates slice objects to concatenation along the first axis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x, bins=8, normed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kde\n",
    "\n",
    "density = kde.gaussian_kde(x)\n",
    "xgrid = np.linspace(x.min(), x.max(), 100)\n",
    "plt.hist(x, bins=18, normed=True)\n",
    "plt.plot(xgrid, density(xgrid), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "## 4 Estimation\n",
    "* 4.1 Sample mean\n",
    "* 4.2 Variance\n",
    "* 4.3 Standard scores\n",
    "* 4.4 Covariance\n",
    "* 4.5 Pearson,s correlation\n",
    "* 4.6 Spearman's rank correlation\n",
    "<font\\> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's think of a sequence of values: \n",
    "[-0.441, 1.774, -0.101, -1.138, 2.975, -2.138].\n",
    "\n",
    "Can you guess which is the distribution? For example what would be its mean?\n",
    "\n",
    "Hint: assume that it is normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Definition:** *Estimation* is the process of inferring the parameters (e.g. mean) of a distribution from a statistic of samples drown from a population.\n",
    "\n",
    "For example: What is the estimated mean $\\hat{\\mu}$ of the following normal data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(0.0, 1.0, 10000)\n",
    "a = plt.hist(x,50,normed='True')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use our definition of empirical mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The empirical mean of the sample is ', x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us imagine that we were reported the following data, where probably one of the data is wrong:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-0.441, 1.774, -0.101, -1.138, 2.975, -213.8])\n",
    "print('The mean is: ', x.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the mean estimator good enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Sample mean\n",
    "\n",
    "+ The process is called **estimation** and the statistic we used **estimator**.\n",
    "\n",
    "+ The median is also an estimator (more robust to outliers). \n",
    "\n",
    "+ \"Is median better than sample mean?\" is a question with at least two different answers. We can use two different objectives to answer this question: the minimization of error or the maximization to get the right answer. \n",
    "\n",
    "+ If there are no outliers, we can use the **sample mean** to minimize **mean squared error** (where $m$ is the number of times you play the estimation game, not the size of the sample!):\n",
    "\n",
    "$$ MSE = \\frac{1}{m} \\sum(\\hat{\\mu} - \\mu)^2$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = 0.0\n",
    "mu=0.0\n",
    "NTests=1000\n",
    "var=1.0\n",
    "NPoints=100000\n",
    "for i in range(NTests):\n",
    "    x = np.random.normal(mu, var, NPoints)\n",
    "    err += (mu - x.mean())**2\n",
    "\n",
    "print('MSE: ', err/float(NTests) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Variance\n",
    "\n",
    "We can also estimate the variance with:\n",
    "\n",
    "$$ \\hat{\\sigma}^2 = \\frac{1}{n} \\sum_i (x_i - \\mu)^2 $$\n",
    "\n",
    "This estimator works for large samples, but it is biased for small samples. We can use this one:\n",
    "\n",
    "$$ \\hat{\\sigma}^2_{n-1} = \\frac{1}{n-1} \\sum_i (x_i - \\mu)^2 $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Other concepts: Standard scores\n",
    "\n",
    "$$ z_i = \\frac{x_i - \\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This measure is dimensionless and its distribution has mean 0 and variance 1.\n",
    "\n",
    "It inherits the \"shape\" of $X$: if it is normally distributed, so is $Z$. If $X$ is skewed, so is $Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Covariance (optional)\n",
    "\n",
    "Sometimes it would be of interest to measure the relationship between two variables. \n",
    "\n",
    "**Covariance** is a measure of the tendency of two variables to vary together. \n",
    "\n",
    "If we have two series $X$ and $Y$ with $X=\\{x_i\\}$ and $Y=\\{y_i\\}$, and they vary together, their deviations $x_i - \\mu_X$ and $y_i - \\mu_Y$ tend to have the same sign.\n",
    "\n",
    "If we multiply them together, the product is positive, when the deviations have the same sign, and negative, when they have the opposite sign. So adding up the products gives a measure of the tendency to vary together.\n",
    "\n",
    "Covariance is the mean of the products:\n",
    "\n",
    "$$ Cov(X,Y) = \\frac{1}{n} \\sum (x_i - \\mu_X)*(y_i - \\mu_Y), $$\n",
    "\n",
    "where $n$ is the length of the two series.\n",
    "\n",
    "It is a measure that is difficult to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cov(X, Y):\n",
    "    def _get_dvis(V):\n",
    "        return [v - np.mean(V) for v in V]\n",
    "    dxis = _get_dvis(X)\n",
    "    dyis = _get_dvis(Y)\n",
    "    return np.sum([x * y for x, y in zip(dxis, dyis)])/len(X)\n",
    "\n",
    "X = [5, -1, 3.3, 2.7, 12.2]\n",
    "Y=[10,12,8,9,11]\n",
    "\n",
    "print(\"Cov(X, X) = %.2f\" % Cov(X, X))\n",
    "print(\"Var(X) = %.2f\" % np.var(X))\n",
    "\n",
    "print(\"Cov(X, Y) = %.2f\" % Cov(X, Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/gasolineprice.gif\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Pearson's Correlation\n",
    "\n",
    "Shell we take into account the variance? An alternative is to divide the deviations by $\\sigma$, which yields standard scores, and compute the product of standard scores:\n",
    "\n",
    "$$ p_i = \\frac{(x_i - \\mu_X)}{\\sigma_X} \\frac{(y_i - \\mu_Y)}{\\sigma_Y} $$\n",
    " \n",
    "The mean of these products is:\n",
    "\n",
    "$$ \\rho = \\frac{1}{n} \\sum p_i = \\frac{1}{n} \\sum  \\frac{(x_i - \\mu_X)}{\\sigma_X} \\frac{(y_i - \\mu_Y)}{\\sigma_Y}  $$\n",
    "\n",
    "Or we can rewrite $\\rho$ by factoring out $\\sigma_X$ and $\\sigma_Y$:\n",
    "\n",
    "$$ \\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}$$\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Corr(X, Y):\n",
    "    assert len(X) == len(Y)\n",
    "    return Cov(X, Y) / np.prod([np.std(V) for V in [X, Y]])\n",
    "\n",
    "print(\"Corr(X, X) = %.5f\" % Corr(X, X))\n",
    "\n",
    "Y=np.random.random(len(X))\n",
    "\n",
    "print(\"Corr(X, Y) = %.5f\" % Corr(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/pearson.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $\\rho = 0$, we cannot say that there is no relationship between the variables!\n",
    "\n",
    "Pearson's coefficient only measures **linear** correlations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Spearman’s rank correlation\n",
    "\n",
    "Pearson’s correlation works well if the relationship between variables is linear and if the variables are roughly normal. But it is not robust in the presence of **outliers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman’s rank correlation is an alternative that mitigates the effect of outliers and skewed distributions. To compute Spearman’s correlation, we have to compute the rank of each value, which is its index in the sorted sample. \n",
    "\n",
    "For example, in the sample {7, 1, 2, 5} the rank of the value 5 is 3, because it appears third if we sort the elements. \n",
    "\n",
    "Then, we compute the Pearson’s correlation, **but for the ranks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2rank(l):\n",
    "    #l is a list of numbers\n",
    "    # returns a list of 1-based index; mean when multiple instances\n",
    "    return [np.mean([i+1 for i, sorted_el in enumerate(sorted(l)) if sorted_el == el]) for el in l]\n",
    "\n",
    "l = [7, 1, 2, 5]\n",
    "print(\"ranks: \", list2rank(l))\n",
    "\n",
    "def spearmanRank(X, Y):\n",
    "    # X and Y are same-length lists\n",
    "    return Corr(list2rank(X), list2rank(Y))\n",
    "\n",
    "X = [1, 2, 3, 4, 100]\n",
    "Y = [5, -100, 7, 10, 9]\n",
    "plt.plot(X,'ro')\n",
    "plt.plot(Y,'go')\n",
    "\n",
    "print(\"Pearson rank coefficient: %.2f\" % Corr(X, Y))\n",
    "print(\"Spearman rank coefficient: %.2f\" % spearmanRank(X, Y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Obtain for the Anscombe's quartet, the different estimators (mean, variance, covariance for each pair, Pearson's correlation and Spearman's rank correlation.\n",
    "\n",
    "(Source: http://en.wikipedia.org/wiki/Anscombe's_quartet):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/Anscombe's_quartet.png\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice:** Show if there is a correlation between the data of the babies...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Main reference\n",
    "*Think Stats: Probability and Statistics for Programmers*, by Allen B. Downey, published by O'Reilly Media.\n",
    "http://www.greenteapress.com/thinkstats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
