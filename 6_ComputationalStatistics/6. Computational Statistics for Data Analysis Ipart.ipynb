{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> \n",
    "# Computational Statistics for Data Analysis\n",
    "<font\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-error\"><strong><center><small>Statistics is the discipline of using data samples to support claims about populations.<small></center></strong> </div>\n",
    "\n",
    "Statistics is based on 2 main concepts:\n",
    "\n",
    "* A **population** is a collection of objects, items (“units”) about which information is sought.\n",
    "\n",
    "* A **sample** is a part of the population that is observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Descriptive Statistics.\n",
    "* 1.1 Getting data\n",
    "* 1.2 Data preparation\n",
    "* 1.3 Improving data as a pandas DataFrame\n",
    "* 1.4 Data cleaning and preparation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Exploratory Data Analysis.\n",
    "* 2.1 Summarizing the data: mean, variance, median, quantiles & percentiles\n",
    "* 2.2 Histogram\n",
    "* 2.3 Data distributions\n",
    "* 2.3.1 PMF\n",
    "* 2.3.2 CDF\n",
    "* 2.4 Outliers\n",
    "* 2.5 Measuring asymmetry  (optional)\n",
    "* 2.5.1 Skewness\n",
    "* 2.5.2 Pearson's median skewness coefficient\n",
    "* 2.6 Relative risk\n",
    "* 2.7 A firts glimpse to Conditional Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<center><img src=\"images/taft_puck_eggdig.jpg\">\n",
    "</center><center><img src=\"images/eggs.png\"></center>\n",
    "<center><small>Headline from Chicago Tribune June 13, 1897.</small></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more: \"http://ptara.com/2011/12/17/never-eat-eggs-with-an-angry-stomach/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Do firts babies arrive late?\"\n",
    "\n",
    "       From [Think Stats: Probability and Statistics for Programmers](http://www.greenteapress.com/thinkstats/), by Allen B. Downey, published by O'Reilly Media.\n",
    "\n",
    "Some people believe it is true, but **without data analysis** to support it, this claim is a case of **anecdotal evidence**:\n",
    "\n",
    "* There are a **small number of samples** (personal experience, friends, etc.).\n",
    "* There is a **selection bias**: most *believers* are interested in this claim because their first babies were late.\n",
    "* There is a **confirmation bias**: believers might be more likely to contribute data that confirm it.\n",
    "* Sources are **innaccurate**: personal stories are subject to memory deformations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "# 1 Descriptive Statistics.\n",
    "* 1.1 Getting data\n",
    "* 1.2 Data preparation\n",
    "* 1.3 Improving data as a pandas DataFrame\n",
    "* 1.4 Data cleaning \n",
    " <font\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Getting Data\n",
    "\n",
    "There is an interesting and publicly available **data source** to check this claim. Since 1973 the U.S. Centers for Disease Control and Prevention (CDC) have conducted a survey, the National Survey of Family Growth (NSFG), to gather *information on family life, marriage and divorce, pregnancy, infertility, use of contraception, and men's and women's health.* \n",
    "\n",
    "Data can be downloaded from: \n",
    "\n",
    "http://www.cdc.gov/nchs/nsfg/nsfg_cycle6.htm#cyc6downdatafiles\n",
    "\n",
    "We will use this file: \n",
    "\n",
    "* Female Pregnancy Data File (2002FemPreg.dat): one record for each pregnancy reported by a respondent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 13593 pregnancies in our data. The meaning of the data is (each record is in a line):\n",
    "\n",
    "+ <code>case.id</code> is the ID of the respondent. From col 1 to 12.\n",
    "+ <code>prg.lenght</code> is the duration of the pregnancy in weeks. From col 275 to 276. \n",
    "+ <code>outcome</code> is the outcome of the pregnancy (1 = live birth). Col 277.\n",
    "+ <code>birth.ord</code> is the integer birth order of each live birth. From col 278 to 279.\n",
    "+ <code>final.wgt</code> is the statistical weight associated to the respondent (it is a floating point value that indicates the number of people in the U.S. population this respondent represents). From col 423 to 440."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<small> If curious: Online documentation of the survey is at http://www.icpsr.umich.edu/nsfg6.<small> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data preparation\n",
    "\n",
    "One of the reasons we are using a general-purpose language such as Python rather than a stats language like R is that for many projects the *hard* part is preparing the data, not doing the analysis.\n",
    "\n",
    "The most common steps are:\n",
    "\n",
    "1. **Getting the data**. Data can be directly read from a file or it might be necessary to scrap the web.\n",
    "2. **Parsing the data**.  Of course, this depends on what format it is in: plain text, fixed columns, CSV, XML, HTML, etc.\n",
    "3. **Cleaning the data**.  Survey responses and other data files are almost always incomplete.  Sometimes there are multiple codes for things like, *not asked*, *did not know*, and *declined to answer*. And there are almost always errors. A simple strategy is to remove or ignore incomplete records.\n",
    "4. **Building data structures**. Once you read the data, you usually want to store it in a data structure that lends itself to the analysis you want to do.\n",
    "\n",
    "If the data fits into memory, building a data structure is usually the way to go.   If not, you could build a **database**, which is an out-of-memory data structure. Most databases provide a mapping from keys to values, so they are like dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('files/2002FemPreg.dat', 'r')\n",
    "\n",
    "# Let's build a list of lists.\n",
    "\n",
    "preg=[]\n",
    "for line in file:\n",
    "    preg.append([int(line[:12]), int(line[274:276]), int(line[276]),\n",
    "                 int(line[277:279]), float(line[422:440])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops! There is something wrong in the data file!\n",
    "\n",
    "By inspecting the data we can observe that there are some empty records that caused an error to the ``int`` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('files/2002FemPreg.dat', 'r')\n",
    "\n",
    "def chr_int(a):\n",
    "    if a == '  ':\n",
    "        return 0\n",
    "    else:\n",
    "        return int(a)\n",
    "        \n",
    "preg=[]\n",
    "for line in file:\n",
    "    lst  = [int(line[:12]), int(line[274:276]), int(line[276]), \\\n",
    "                 chr_int(line[277:279]), float(line[422:440])]\n",
    "    preg.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preg[1])\n",
    "print('The number of lines read is: ', len(preg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Importing data as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(preg) #  Two-dimensional size-mutable, potentially heterogeneous tabular data structure with labeled axes \n",
    "# http://pandas.pydata.org/pandas-docs/dev/dsintro.html#dataframe\n",
    "\n",
    "df.columns = ['caseId', 'prgLength', 'outcome', 'birthOrd', 'finalWgt']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count the number of  births according to the order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby('birthOrd').size()\n",
    "print(counts[1])\n",
    "print(counts) \n",
    "\n",
    "# also: df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a partition of *live births* into two groups: first babies and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide records into two lists: first babies and others.\n",
    "\n",
    "firstbirth = df[ (df.outcome == 1) & (df.birthOrd == 1)]\n",
    "firstbirth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othersbirth = df[(df.outcome == 1) & (df.birthOrd >= 2)]\n",
    "othersbirth.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Data Cleaning\n",
    "\n",
    "The most common steps are:\n",
    "\n",
    "+ **Sample the data**. If the amount of raw data is huge, processing all of them may require an extensive amount of processing power which may not be practical.  In this case, it is quite common to sample the input data to reduce the size of data that need to be processed.\n",
    "\n",
    "+ **Impute missing data**. It is quite common that some of the input records are incomplete in the sense that certain fields are missing or have input error.  In a typical tabular data format, we need to validate each record contains the same number of fields and each field contains the data type we expect. In case the record has some fields missing, we have the following choices: \n",
    "<small>\n",
    "* (a) Discard the whole record if it is incomplete; \n",
    "* (b) Infer the missing value based on the data from other records.  A common approach is to fill the missing data with the average, or the median.\n",
    "<small>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Normalize numeric value**. Normalize data is about transforming numeric data into a uniform range.\n",
    "+ **Reduce dimensionality**. High dimensionality can be a problem for some machine learning methods.  There are two ways to reduce the number of input features.  One is about $removing$ $irrelevant$ input variables, another one is about $removing$ $redundant$ input variables.\n",
    "+ **Add derived features**. In some cases, we may need to compute additional attributes from existing attributes (f.e. converting a geo-location to a zip code, or converting the age to an age group).\n",
    "+ **Discretize numeric value into categories**. Discretize data is about cutting a continuous value into ranges and assigning the numeric with the corresponding bucket of the range it falls on.  For numeric attribute, a common way to generalize it is to discretize it into ranges, which can be either constant width (variable height/frequency) or variable width (constant height).\n",
    "+ **Binarize categorical attributes**. Certain machine learning models only take binary input (or numeric input).  In this case, we need to convert categorical attribute into multiple binary attributes, while each binary attribute corresponds to a particular value of the category. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Select, combine, aggregate data**. Designing the form of training data is the most important part of the whole predictive modeling exercise because the accuracy largely depends on whether the input features are structured in an appropriate form that provide strong signals to the learning algorithm. Rather than using the raw data as it is, it is quite common that multiple pieces of raw data need to be combined together, or aggregating multiple raw data records along some dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "## 2 Exploratory Data Analysis.\n",
    "* 2.1 Summariizing the data: mean, variance, median, quantiles & percentiles\n",
    "* 2.2 Histogram\n",
    "* 2.3 Data distributions\n",
    "* 2.3.1 PMF\n",
    "* 2.3.2 CDF\n",
    "* 2.4 Outliers\n",
    "* 2.5 Measuring asymmetry\n",
    "* 2.5.1 Skewness\n",
    "* 2.5.2 Pearson's median skewness coefficient\n",
    "* 2.6 Relative risk\n",
    "* 2.7 A firts glimpse to Conditional Probability\n",
    "<font\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Summarizing the data: \n",
    "#### 2.1.1 Sample Mean \n",
    "\n",
    "If you have a sample of $n$ values, $x_i$, the **sample mean** is the sum of the values divided by the number of values:\n",
    "\n",
    "$$ \\mu = \\frac{1}{n} \\sum_i x_i$$\n",
    "\n",
    "The **mean** is the most basic and important summary statistic. It describes the central tendency of a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if there is a difference between firstbirth and othersbirth:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(firstbirth['prgLength'].mean(), othersbirth['prgLength'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(firstbirth['prgLength'].mean()-\n",
    "          othersbirth['prgLength'].mean()),\"weeks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(firstbirth['prgLength'].mean()-\n",
    "          othersbirth['prgLength'].mean())*7,\"days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(firstbirth['prgLength'].mean()-\n",
    "          othersbirth['prgLength'].mean())*7*24, \"hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This difference in sample means can be considered a first evidence of our hypothesis!\n",
    "\n",
    "\n",
    "**Comment: ** *Later, we will work with both concepts: the population mean and the sample mean. Do not confuse them! Remember, the first one is the mean of samples taken from the population and the second one is the mean of the whole population.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Sample Variance\n",
    "\n",
    "Usually, mean is not a sufficient descriptor of the data, we can do a little better with two numbers: mean and **variance**:\n",
    "\n",
    "$$ \\sigma^2 = \\frac{1}{n} \\sum_i (x_i - \\mu)^2 $$\n",
    "\n",
    "**Variance** $\\sigma^2$ describes the *spread* of data. The term $(x_i - \\mu)$ is called the *deviation from the mean*, so variance is the mean squared deviation.\n",
    "\n",
    "The square root of variance, $\\sigma$, is called the **standard deviation**. We define standard deviation because variance is hard to interpret (in the case the units are grams, the variance is in grams squared).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1 = firstbirth['prgLength'].mean()\n",
    "mu2 = othersbirth['prgLength'].mean()\n",
    "var1 = firstbirth['prgLength'].var()\n",
    "var2 = othersbirth['prgLength'].var()\n",
    "std1 = firstbirth['prgLength'].std()\n",
    "std2 = othersbirth['prgLength'].std()\n",
    "print('mu1:', mu1, 'var1:', var1, 'std1:', std1)\n",
    "print('mu2:', mu2, 'var2:', var2, 'std2:', std2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Sample Median\n",
    "\n",
    "The statistical median is an order statistic that gives the *middle* value of a sample. It is a value more robust to ouliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"images/mean_median.gif\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median1= firstbirth['prgLength'].median()\n",
    "median2= othersbirth['prgLength'].median()\n",
    "print(median1, median2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Summarizing the data: Quantiles & Percentiles\n",
    "\n",
    "Order the sample $\\{ x_i \\}$, then find $x_p$ so that it divides the data into two parts where:\n",
    "\n",
    "+ a fraction $p$ of the data values are less than or equal to $x_p$ and\n",
    "+ the remaining fraction $(1 − p)$ are greater than $x_p$.\n",
    "\n",
    "That value $x_p$ is the pth-quantile, or 100×pth percentile.\n",
    "\n",
    "**5-number summary**: $x_{min}, Q_1, Q_2, Q_3, x_{max}$, where $Q_1$ is the 25×pth percentile,\n",
    "$Q_2$ is the 50×pth percentile and $Q_3$ is the 75×pth percentile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common representation of a distribution is a **histogram**, which is a graph that shows the frequency of each value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb=firstbirth['prgLength']\n",
    "\n",
    "fb.hist(normed=0, histtype='stepfilled', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "ob=othersbirth['prgLength']\n",
    "ob.hist(normed=0, histtype='stepfilled', bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fb.hist(normed=1, histtype='stepfilled', alpha=.5)   # default number of bins = 10\n",
    "ob.hist(normed=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Computes several descriptive statistics:\n",
    "# size of the data \n",
    "# minimum and maximum value of data array\n",
    "# arithmetic mean \n",
    "# unbiased variance \n",
    "# biased skewness \n",
    "# kurtosis (Fisher)\n",
    "\n",
    "stats.describe(othersbirth['prgLength'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Distributions\n",
    "\n",
    "Summarizing can be dangerous: very different data can be described by the same statistics. It must be validated by inspecting the data.\n",
    "\n",
    "We can look at the **data distribution**, which describes how often (frequency) each value appears.\n",
    "\n",
    "\n",
    "We can normalize the frequencies of the histogram by dividing/normalizing by $n$, the number of samples. The normalized histogram is called **Probability Mass Function (PMF)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if needed, execute the command 'pip3 install seaborn'\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "x = firstbirth['prgLength']\n",
    "y = othersbirth['prgLength']\n",
    "\n",
    "x.hist(normed=1, histtype='stepfilled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.hist(normed=1, histtype='stepfilled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cumulative distribution function (CDF)**, or just distribution function, describes the probability that a real-valued random variable X with a given probability distribution will be found to have a value less than or equal to x. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.hist(normed=1, histtype='step', cumulative=True, linewidth=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob.hist(normed=1, histtype='step', cumulative=True, linewidth=3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.hist(bins=10, normed=1, histtype='stepfilled', alpha=.5)   # default number of bins = 10\n",
    "ob.hist(bins=10, normed=1, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))\n",
    "\n",
    "# Check with 20, 30, 60 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb.hist(normed=1, histtype='step', cumulative=True,  linewidth=3.5, bins=30)\n",
    "ob.hist(normed=1, histtype='step', cumulative=True,  linewidth=3.5, bins=30, color=sns.desaturate(\"indianred\", .75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean sample difference is \", x.mean() - y.mean(), \"weeks.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Outliers\n",
    "\n",
    "**Ouliers** are data samples with a value that is far from the central tendency.\n",
    "\n",
    "We can find outliers by:\n",
    "\n",
    "+ Computing samples that are *far* from the median.\n",
    "+ Computing samples whose value *exceeds the mean* by 2 or 3 standard deviations.\n",
    "\n",
    "This expression will return a series of boolean values that you can then index the series by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.outcome == 1) & (df['prgLength'] < df['prgLength'].median() - 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prgLength'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.outcome == 1) & (df['prgLength'] < df['prgLength'].median() - 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df.outcome == 1) & (df['prgLength'] > df['prgLength'].median() + 6)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we think that outliers correspond to errors, an option is to trim the data by discarting the highest and lowest values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(df.index[(df.outcome == 1) & (df['prgLength'] > df['prgLength'].median() + 6)])\n",
    "df2[(df2.outcome == 1) & (df2['prgLength'] > df2['prgLength'].median() + 6)] # check if removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.drop(df2.index[(df2.outcome == 1) & (df2['prgLength'] < df2['prgLength'].median() - 10)])\n",
    "df3[(df3.outcome == 1) & (df3['prgLength'] < df3['prgLength'].median() - 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstbirth3 = df3[(df3.outcome == 1) & (df3.birthOrd == 1)]\n",
    "mu3fb = firstbirth3['prgLength'].mean()\n",
    "std3fb = firstbirth3['prgLength'].std()\n",
    "md3fb = firstbirth3['prgLength'].median()\n",
    "print(mu3fb, std3fb, md3fb, firstbirth3['prgLength'].min(),\n",
    "      firstbirth3['prgLength'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othersbirth3 = df3[(df3.outcome == 1) & (df3.birthOrd >= 2)]\n",
    "mu3ob = othersbirth3['prgLength'].mean()\n",
    "std3ob = othersbirth3['prgLength'].std()\n",
    "md3ob = othersbirth3['prgLength'].median()\n",
    "print(mu3ob, std3ob, md3ob, firstbirth3['prgLength'].min(), \n",
    "      firstbirth3['prgLength'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The mean sample difference is: \",)\n",
    "print(firstbirth3['prgLength'].mean() - \n",
    "      othersbirth3['prgLength'].mean(), \"weeks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df3.prgLength[(df3.outcome == 1)]))\n",
    "print(len(df.prgLength[(df.outcome == 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "\n",
    "df3.prgLength[(df3.outcome == 1)].plot(alpha=.5, color='blue')\n",
    "df.prgLength[(df.outcome == 1)].plot(alpha=.5, \n",
    "                            color=sns.desaturate(\"indianred\", .95))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is happening near the mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = firstbirth3['prgLength']\n",
    "y = othersbirth3['prgLength']\n",
    "\n",
    "countx,divisionx = np.histogram(x) \n",
    "county,divisiony = np.histogram(y)\n",
    "print (countx-county)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(15,3))\n",
    "val = [(divisionx[i]+divisionx[i+1])/2 for i in range(len(divisionx)-1)]\n",
    "plt.plot(val, countx-county, 'o-') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still some evidence for our hypothesis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The means are: ', x.mean(), y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**:\n",
    "\n",
    "+ Read the file ``run10.txt`` from the ``files`` directory. It represents 16.924 runners who finished the 2012 Cherry Blossom 10 mile run in USA. The file is a ``tab``separated file. It can be read with the pandas ``read_table`` function.\n",
    "+ Compute the mean time.\n",
    "+ Compute the difference in mean between men and women.\n",
    "+ Visualize both distributions (normalized histogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Measuring asymmetry.\n",
    "\n",
    "** Skewness** is a statistic that measures the asymmetry of set of $n$ data samples $x_i$:\n",
    "\n",
    "$$ g_1 = \\frac{\\frac{1}{n} \\sum_i (x_i - \\mu)^2 }{\\frac{1}{n} \\sum_i (x_i - \\mu)^3 }$$\n",
    "\n",
    "The numerator is the mean squared deviation (or variance) and the denominator the mean cubed deviation.\n",
    "\n",
    "Negative deviation indicates that the distribution \"skews left\" (it extends farther to the left than to the right).\n",
    "\n",
    "** Skewness** can be affected by outliers!!! A simpler alternative is to look at the relationship between mean ($\\mu$) and median ($\\mu_{\\frac{1}{2}}$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2.6 Pearson's median skewness coefficient** is a more robust alternative:\n",
    "\n",
    "$$ g_p = \\frac{3(\\mu - \\mu_{\\frac{1}{2}})}{\\sigma} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Write a function to compute $g_1$ and $g_p$ of the pregnancy length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercises**: \n",
    "\n",
    "+ Could you give a real example, where for all data samples, $x_i \\leq \\mu$? \n",
    "+ Could you give a real example, where for all data samples, $x_i \\leq \\mu_{\\frac{1}{2}}$? This is really a distribution that skews left!\n",
    "+ If we ask to a random group of people \"What is your position with respect to the average driver?\", what kind of distribution would we get? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Relative Risk\n",
    "\n",
    "Let's say that a baby is \"early\" if it is born during week 37 or earlier, \"on time\" if it is born during week 38, 39 or 40, and \"late\" if it is born during week 41 or later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstbirth3 = df3[(df3.outcome == 1) & (df3.birthOrd == 1)]\n",
    "firstbirth3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the probability of being *early*, *on time* and *late* for first babies and the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Firsts babies: \")\n",
    "print(\"Early\",len(firstbirth3[firstbirth3['prgLength'] <38])/\n",
    "      float(len(firstbirth3.index)))\n",
    "print(\"Late\", len(firstbirth3[firstbirth3['prgLength'] >40])/\n",
    "      float(len(firstbirth3.index)))\n",
    "print(\"On time\", len(firstbirth3[(firstbirth3['prgLength'] >37) &\n",
    "    (firstbirth3['prgLength'] < 41)])/float(len(firstbirth3.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Other babies:\")\n",
    "print(\"Early\", len(othersbirth3[othersbirth3['prgLength'] <38])/\n",
    "      float(len(othersbirth3.index)))\n",
    "print(\"Late\", len(othersbirth3[othersbirth3['prgLength'] >40])/\n",
    "      float(len(othersbirth3.index)))\n",
    "print(\"On time\", len(othersbirth3[(othersbirth3['prgLength'] >37) &\n",
    "    (othersbirth3['prgLength']<41)])/float(len(othersbirth3.index)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **relative risk** is the ratio of two probabilities. In our case, the probability that a first baby is born early is 17%. For other babies is 16%, so the relative risk is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(firstbirth3[firstbirth3['prgLength'] <38])/float(len(firstbirth3.index))\n",
    "b = len(othersbirth3[othersbirth3['prgLength'] <38])/float(len(othersbirth3.index))\n",
    "print(\"First babies are about \", a/b, \" more likely to be early.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that first babies are about 7% more likely to be early. For the case of late births:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = len(firstbirth3[firstbirth3['prgLength'] >40])/float(len(firstbirth3))\n",
    "b = len(othersbirth3[othersbirth3['prgLength'] >40])/float(len(othersbirth3))\n",
    "print(\"First babies are about \", a/b, \" more likely to be late.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That means that first babies are about 67% more likely to be late. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 A firts glimpse to Conditional Probability\n",
    "\n",
    "Imagine that someone you know is pregnant and it is the beginning of week 39. What is the chance that the baby will be born in the week 39? What is the chance if it is a first baby?\n",
    "\n",
    "We can ask these questions by computing a **conditional probability**, $P(X|Y)$.\n",
    "\n",
    "In our first question, the event $X$ is a birth in week 39 and the event $Y$ is that we know that the baby didn't arrive during weeks 0-38. In the second question, we also know that it is a first baby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple way to compute these chances is to drop from our data the cases that do not fulfill the conditions and then renormalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(df3.index[df3['prgLength'] < 39]) \n",
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df4.prgLength\n",
    "x.hist(bins=6, histtype='stepfilled', alpha=.5)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to compute the probability that the baby will be born in the week 39 for a pregnant woman in the beginning of week 39."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df4[(df4.prgLength == 39)].index)/float(len(df4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add the second condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstbirth39 = df4[(df4.birthOrd == 1)]\n",
    "othersbirth39 = df4[(df4.birthOrd > 1)]\n",
    "x = firstbirth39['prgLength']\n",
    "y = othersbirth39['prgLength']\n",
    "x.hist(bins=6,  normed=True, histtype='stepfilled', alpha=.5)   # default number of bins = 10, blue\n",
    "y.hist(bins=6,  normed=True, histtype='stepfilled', alpha=.5, color=sns.desaturate(\"indianred\", .75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability First baby on week 39: ', \n",
    "    len(firstbirth39[(firstbirth39.prgLength == 39)].index)/\n",
    "    float(len(firstbirth39.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Probability non first baby to be born on week 39: ',\n",
    "    len(othersbirth39[(othersbirth39.prgLength == 39)].index)/\n",
    "    float(len(othersbirth39.index)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussions.\n",
    "\n",
    "After exploring the data we have seem some **appearent effects** that seem to support our first hypothesis:\n",
    "\n",
    "+ **Data description**: The mean pregnant lenght for first babies is 38.76 and for other babies is 38.65.\n",
    "\n",
    "+ **Relative risk**: First babies are about 67% more likely to be late.\n",
    "\n",
    "+ **Conditional probability**: If someone is pregnant and it is the beginning of week 39, the chance (63% vs. 72%) that the baby will be born in the week 39 is lower if it is the first baby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other possible experiments\n",
    "\n",
    "We can compare the first and others for the same woman. While may be unlikely it could still be that a tendency exists for a woman's second, third, etc, child comes earlier.\n",
    "\n",
    "<small>(Result:  The second baby is born about some hours earlier, but this difference is not *statistically significant*.)<small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main reference\n",
    "*Think Stats: Probability and Statistics for Programmers*, by Allen B. Downey, published by O'Reilly Media.\n",
    "http://www.greenteapress.com/thinkstats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
